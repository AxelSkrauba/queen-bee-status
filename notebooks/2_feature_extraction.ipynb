{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir rutas de los archivos originales\n",
    "audio_dir = 'audio_sample'\n",
    "csv_path = 'all_data_updated.csv'\n",
    "\n",
    "# Salida del csv procesado, para test se agrega \"test\" antes del nombre\n",
    "output_path = 'output_file_50mfcc_4000Hz.csv'\n",
    "\n",
    "# Nueva frecuencia de muestreo en Hz, librosa usa un filtro\n",
    "new_sr = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de archivos principales para cada set. 70 % para train por defecto.\n",
    "df = pd.read_csv(csv_path)\n",
    "audios_originales = df['file name']\n",
    "test_audios_originales = audios_originales.sample(frac=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_embeddings(audio_path):\n",
    "    \"\"\"\n",
    "    Función para extraer embeddings de un archivo de audio.\n",
    "    Finalmente se trabaja con los MFCC, YAMNet no presentó buenos resultados.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Re muestreo\n",
    "    if sr != new_sr:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=new_sr)\n",
    "        sr = new_sr\n",
    "\n",
    "    # Usamos librosa para extraer embeddings. Por ejemplo, utilizando MFCC.\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=50)\n",
    "    # Tomamos la media a lo largo del tiempo para obtener un vector de tamaño fijo.\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    return mfcc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con segmentacion de archivos previo a la división\n",
    "def process_audios(audio_dir, csv_path, output_path):\n",
    "    # Leer el archivo CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Crear una lista para almacenar los embeddings y las etiquetas\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    files_name = []\n",
    "\n",
    "    # Lo mismo, para separar set de test\n",
    "    embeddings_t = []\n",
    "    labels_t = []\n",
    "    files_name_t = []\n",
    "    \n",
    "    # Recorrer el directorio de audios\n",
    "    for root, dirs, files in os.walk(audio_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):  # Asumimos que los archivos de audio son .wav\n",
    "                file_base_name = os.path.splitext(file)[0]\n",
    "\n",
    "                if file_base_name[-1] == '5':\n",
    "                    # Omitir los segment5, tienen aliasing\n",
    "                    continue\n",
    "\n",
    "                file_base_name = file_base_name[:-10]\n",
    "                # Verificar si el archivo está en el CSV\n",
    "                matching_rows = df[df['file name'].str.contains(file_base_name)]\n",
    "                \n",
    "                if not matching_rows.empty:\n",
    "                    \"\"\"\n",
    "                    Se procesa el audio existente\n",
    "                    \"\"\"\n",
    "                    audio_path = os.path.join(root, file)\n",
    "                    embedding = extract_audio_embeddings(audio_path)\n",
    "\n",
    "                    # Se determina a qué set corresponde\n",
    "                    train_set_rows = test_audios_originales[test_audios_originales.str.contains(file_base_name)]\n",
    "\n",
    "                    if not train_set_rows.empty:\n",
    "                        # Set de Train\n",
    "\n",
    "                        # Añadir embedding y etiqueta a las listas\n",
    "                        embeddings.append(embedding)\n",
    "                        labels.append(matching_rows.iloc[0]['queen status'])  # Asumimos que hay una columna 'queen status'\n",
    "                        files_name.append(file)\n",
    "                    else:\n",
    "                        # Set de Test\n",
    "                        embeddings_t.append(embedding)\n",
    "                        labels_t.append(matching_rows.iloc[0]['queen status'])  # Asumimos que hay una columna 'queen status'\n",
    "                        files_name_t.append(file)\n",
    "\n",
    "    # Convertir listas a DataFrame\n",
    "\n",
    "    # # Set de Train\n",
    "    embeddings_df = pd.DataFrame(embeddings)\n",
    "    embeddings_df['file name'] = files_name\n",
    "    embeddings_df['label'] = labels\n",
    "    \n",
    "    # Guardar el DataFrame a un archivo\n",
    "    embeddings_df.to_csv(output_path, index=False)\n",
    "\n",
    "    # # Set de Train\n",
    "    embeddings_df_t = pd.DataFrame(embeddings_t)\n",
    "    embeddings_df_t['file name'] = files_name_t\n",
    "    embeddings_df_t['label'] = labels_t\n",
    "    \n",
    "    # Guardar el DataFrame a un archivo\n",
    "    embeddings_df_t.to_csv('test'+output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el procesamiento\n",
    "process_audios(audio_dir, csv_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanlab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
